{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Learning Tutorial for Molecular Property Prediction\n",
    "#### 제작 : 허종국 (hjkso1406@korea.ac.kr)\n",
    "\n",
    "### Introduction\n",
    "본 튜토리얼에서는 준지도학습 알고리즘 중 [Fixmatch](https://arxiv.org/ftp/arxiv/papers/2001/2001.07685.pdf)를 활용해 물성을 예측해보도록 하겠습니다. 물성 예측 벤치마크인 [MoleculeNet Benchmark](https://pubs.rsc.org/en/content/articlehtml/2018/sc/c7sc02664a)는 뇌혈관장벽 투과성, 용해도, 전기음성도 등 양자역학, 물리화학, 생물물리학, 생리학에 아우르는 다양한 물성에 대한 데이터셋을 제공합니다.\n",
    "![Moleculenet](./images/moleculenet.png)\n",
    "\n",
    "MoleculeNet Benchmark의 타겟은 이진 분류 혹은 연속형 회귀 분석으로 나뉩니다. Fixmatch는 분류 문제를 타겟으로 나온 알고리즘이기 때문에 본 튜토리얼에서는 이진 분류 데이터셋 중 하나인 __BACE__ 데이터셋에 대해 Fixmatch를 구현하고자 합니다. 또한 Unlabeled Dataset으로는 Moleculenet Benchmark 의 multi-target regression 데이터 중 하나인 __QM9__ 데이터를 사용하였습니다. BACE 데이터는 총 1513개로 8:1:1 비율로 학습/검증/테스트 데이터를 분할하였으며, QM9 데이터는 130829개 중 일부를 Unlabeled Data로 사용하였습니다.\n",
    "\n",
    "### Requiremnets\n",
    "#### rdkit\n",
    "\n",
    "__python 3.7이하__\n",
    "rdkit 패키지의 설치 명령어는 Python version에 따라 다릅니다.\n",
    "```\n",
    "pip install rdkit \n",
    "```\n",
    "__python 3.8__\n",
    "```\n",
    "conda install -c conda-forge rdkit\n",
    "```\n",
    "\n",
    "### Download Data\n",
    "[링크](https://drive.google.com/file/d/1aDtN6Qqddwwn2x612kWz9g0xQcuAtzDE/view)를 통해 데이터를 다운받으시길 바랍니다. 혹은 `./data` 라는 폴더를 생성한 후 직접 [MoleculeNet](https://moleculenet.org/)에서 다운 받으실 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages & Hyper-parameters\n",
    "* MU - 한 Iteration에서 Labeled Data 개수 대비 Unlabeled Data 개수의 비율을 나타냅니다.\n",
    "* WEIGHT - Unlabeled Loss를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import RDLogger\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data.batch import Batch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from auglichem.molecule import Compose, RandomAtomMask, RandomBondDelete, MotifRemoval\n",
    "from auglichem.molecule.data import MoleculeDatasetWrapper, MoleculeDataset\n",
    "\n",
    "import itertools\n",
    "\n",
    "from model import *\n",
    "from utils import *\n",
    "from dataset import DualMoleculeDataset\n",
    "from loader import DualDataLoader\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "MU = 7\n",
    "BATCH_SIZE = 64\n",
    "THRESHOLD = 0.7\n",
    "WEIGHT = 3.0\n",
    "EPOCHS = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model (GINE)\n",
    "GINE는 Graph Neural Network(GNN) 중 하나로써, [Strategies for Pretraining Graph Neural Netwroks](https://arxiv.org/pdf/1905.12265.pdf) 라는 논문에서 처음 제안되었습니다. 해당 모델은 [How Powerful Are Graph Neural Networks](https://arxiv.org/pdf/1810.00826.pdf)에서 제안한 Graph Isomorphism Network(GIN)을 개선한 모델입니다. 기존의 Graph Convolution 혹은 Message Passing이 __Node Attribute__ 만 고려하였다면, GINE는 __Edge Attribute__ 까지 고려하여 Node Representation을 업데이트한다는 것이 특징입니다.\n",
    "\n",
    "$$ \\mathbf{x}_{i}^{\\prime}=h_{\\boldsymbol{\\Theta}}\\left((1+\\epsilon) \\cdot \\mathbf{x}_{i}+\\sum_{j \\in \\mathcal{N}(i)} \\operatorname{ReLU}\\left(\\mathbf{x}_{j}+\\mathbf{e}_{j, i}\\right)\\right) $$\n",
    "\n",
    "* 출처 - https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GINEConv\n",
    "\n",
    "이러한 GINE의 특성은 다양한 종류와 그에 따라 상이한 성질을 가지는 원자간 결합(Edge)를 반영하기 적합하기 때문에 본 튜토리얼에서 모델로 차용하였습니다. GINE 모델 구현이 궁금하신 분은 model.py를 참조해주시면 되겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GINE(drop_ratio=0.3)\n",
    "device = torch.device('cuda:0')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Weak & Strong Augmentation\n",
    "\n",
    "분자를 그래프로 표현하였을 경우 데이터 증강 기법은 크게 아래 3가지로 나눌 수 있습니다.\n",
    "\n",
    "![Augmentation](./images/Augmentation.png)\n",
    "\n",
    "Fixmatch를 적용하기 위해서는 이미지와 같이 그래프에서도 Weak Augmentation과 Strong Augmentation을 적용해야합니다. 본 튜토리얼에서는 __결합 정보 보존 유무__ 에 따라 Weak와 Strong Augmentation을 정의하였습니다. 따라서 본 튜토리얼에서는 __atom masking__ 을 Weak Augmentation으로, __atom & bond masking__ 을 Strong Augmentation으로 정의하였습니다. 이외에도 __AugliChem__ 패키지에서 제공하는 Motif(Sub-graph) Removal 를 Strong Augmentation으로 정의할 수 도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_aug = Compose([RandomAtomMask([0.1, 0.3])])\n",
    "s_aug1 = Compose([RandomAtomMask([0.1, 0.3]),\n",
    "                  RandomBondDelete([0.1, 0.3])])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Dataset & DataLoader\n",
    "그래프 데이터는 배치를 구성하는데 있어서 이미지와 전혀 다른 프로세스를 가집니다. 이미지의 경우, __(C, H, W)__ 차원의 __N__ 개의 텐서를 스태킹하여 (N, C, H, W)의 4차원 텐서로 변환합니다. 하지만 그래프 데이터의 경우는 이러한 방식으로 텐서를 스태킹할 수 없습니다. 그래프 데이터에서 배치 구성은 N개의 그래프에 대한 __Node Attribute, Edge Attribute, Adjacency Matrix__ 를 __모두 하나의 그래프__ 로 만듭니다. 자세한 사항은 [링크](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html)를 참조해주세요!\n",
    "\n",
    "그래프 데이터에서 Fixmatch를 적용하기 위해 Weak Augmentation과 Strong Augmentation된 배치가 병렬적으로 생성될 수 있어야합니다. __AugliChem__ 패키지의 __MoleculeDataset__ 을 변형하여 커스텀 데이터셋/데이터로더인 __DualMoleculeDataset__ 과 __DualDataLoader__ 를 구현하였습니다. 자세한 사항은 dataset.py와 dataloader.py를 참조해주세요!!\n",
    "\n",
    "* Caution : 기존의 MoleculeNet Benchmark의 대다수 데이터는 __Random Split__ 이 아닌 __Scaffold Split__ 을 사용하는 것이 원칙입니다. 학습/검증/테스트 데이터가 서로 다른 __Scaffold__ 를 가지도록하여 __Out-of-Distribution(OOD)__ 상황에서도 강건하게 예측해야하기 떄문입니다. 하지만 본 튜토리얼에서는 Class Distribution의 Mismatch나 OOD를 해결하는 것이 목적이 아니기 때문에, 원활한 학습을 위해 Random Split을 사용합니다.\n",
    "\n",
    "#### Scaffold Split이란??\n",
    "스캐폴드(Scaffold)란 분자를 이루고 있는 기본적인 골격 뼈대를 의미합니다. 각 분자별로 가지고 있는 Scaffold는 같을 수도 있고 다를 수도 있습니다. 스캐폴드의 예시는 아래 그림과 같습니다.\n",
    "![Scaffold](./images/scaffold.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_dataset = MoleculeDatasetWrapper(dataset=\"BACE\",\n",
    "                                         data_path='./data',\n",
    "                                         transform=w_aug,\n",
    "                                         split=\"random\",\n",
    "                                         batch_size=BATCH_SIZE)\n",
    "train_loader_labeled, val_loader, test_loader = labeled_dataset.get_data_loaders()\n",
    "\n",
    "unlabeled_dataset = DualMoleculeDataset(dataset=\"QM9\",\n",
    "                                    data_path='./data',\n",
    "                                    s_transform=s_aug1,\n",
    "                                    w_transform=w_aug,\n",
    "                                    test_mode=False,\n",
    "                                    _training_set=True,\n",
    "                                    _train_warn=False,)\n",
    "train_loader_unlabeled = DualDataLoader(unlabeled_dataset, batch_size = MU * BATCH_SIZE, drop_last=False, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Trainer(FixMatch)\n",
    "![FixMatch](./images/fixmatch.png)\n",
    "Fixmatch는 두 가지 학습을 동시에 진행합니다.\n",
    "\n",
    "1.\n",
    "    Labeled Data에 대해 Weak Augmentation을 수행한 후 지도학습 수행\n",
    "\n",
    "\n",
    "2.\n",
    "    Unlabeled Data에 대해 Strong Augmentation과 Weak Augmentation을 적용후 예측\n",
    "    Weak Augmentation의 예측 값에 대해 Threshold 이상의 Confidency를 가질 경우, Pseudo-label로 지정\n",
    "    Strong Augmentation의 예측 값에 대해 Pseudo-label을 따라가도록 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_step_semi(model: nn.Module,\n",
    "                     batch: Batch,\n",
    "                     meters: AverageMeterSet,\n",
    "                     device:torch.device):\n",
    "    \n",
    "    l_batch, (u_w, u_s) = batch\n",
    "    x_w, labels = l_batch, l_batch.y.reshape(-1)\n",
    "    \n",
    "    labels = labels.to(device)\n",
    "    total_x_batch = list(itertools.chain.from_iterable([b.to_data_list() for b in [l_batch, u_w, u_s]]))\n",
    "    total_x_batch = Batch.from_data_list(total_x_batch).to(device)\n",
    "    \n",
    "    _, total_logits = model(total_x_batch)\n",
    "    logits_x = total_logits[:len(l_batch)]\n",
    "    logits_u_w, logits_u_s = total_logits[len(l_batch):].chunk(2)\n",
    "    \n",
    "    labeled_loss = F.cross_entropy(logits_x, labels, reduction='mean')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pseudo_labels = torch.softmax(logits_u_w, dim=1)\n",
    "        max_probs, targets_u = torch.max(pseudo_labels, dim=1)\n",
    "        mask = max_probs.ge(THRESHOLD).float()\n",
    "    \n",
    "    unlabeled_loss = (F.cross_entropy(logits_u_s, targets_u, reduction=\"none\") * mask).mean()\n",
    "    \n",
    "    loss = labeled_loss.mean() + WEIGHT * unlabeled_loss\n",
    "    \n",
    "    meters.update(\"total_loss\", loss.item(), 1)\n",
    "    meters.update(\"labeled_loss\", labeled_loss.mean().item(), logits_x.size()[0])\n",
    "    meters.update(\"unlabeled_loss\", unlabeled_loss.item(), logits_u_s.size()[0])\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_semi(model: nn.Module,\n",
    "                     ema_model: EMA,\n",
    "                     train_loader_labeled: DataLoader,\n",
    "                     train_loader_unlabeled: DataLoader,\n",
    "                     optimizer: torch.optim.Adam,\n",
    "                     scaler: GradScaler,\n",
    "                     device: torch.device):\n",
    "    \n",
    "    meters = AverageMeterSet()\n",
    "    \n",
    "    model.train()\n",
    "    with tqdm(**get_tqdm_config(total=len(train_loader_labeled), leave=True, color='cyan')) as pbar:\n",
    "        for idx, batch in enumerate(zip(train_loader_labeled, train_loader_unlabeled)):\n",
    "            with autocast():\n",
    "                loss = _train_step_semi(model, batch, meters, device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            ema_model(model)\n",
    "            pbar.set_description(f\"[Train(Batch)-- Idx: {idx + 1}| Train(Total) Loss : {meters['total_loss'].avg:.4f} | Train(Labeled) Loss : {meters['labeled_loss'].avg:.4f} | Train(Unlabeled) Loss : {meters['unlabeled_loss'].avg}\")\n",
    "            pbar.update(1)\n",
    "        pbar.set_description(f\"[Train(Epoch)-- Idx: {idx + 1}| Train(Total) Loss : {meters['total_loss'].avg:.4f} | Train(Labeled) Loss : {meters['labeled_loss'].avg:.4f} | Train(Unlabeled) Loss : {meters['unlabeled_loss'].avg}\")\n",
    "    \n",
    "    return meters['total_loss'].avg, meters['labeled_loss'].avg, meters['unlabeled_loss'].avg  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "평가지표로는 ROC-AUC를 사용하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics = namedtuple(\n",
    "    \"evaluation_metrics\",\n",
    "    [\"loss\", \"roc_auc\"],)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model:nn.Module,\n",
    "             loader:DataLoader,\n",
    "             device:torch.device,\n",
    "             desc:str):\n",
    "\n",
    "    preds_logit = []\n",
    "    targets_binary = []\n",
    "    \n",
    "    meters = AverageMeterSet()\n",
    "    \n",
    "    model.eval()\n",
    "    with tqdm(**get_tqdm_config(total=len(loader), leave=True, color='magenta')) as pbar:\n",
    "        for idx, batch in enumerate(loader):\n",
    "            batch = batch.to(device)\n",
    "            _, pred = model(batch)\n",
    "            loss = F.cross_entropy(pred, batch.y.reshape(-1), reduction='mean')\n",
    "\n",
    "            preds_logit.extend(F.softmax(pred, dim=-1).detach().cpu().numpy())\n",
    "            targets_binary.extend(batch.y.reshape(-1).detach().cpu().numpy())\n",
    "            \n",
    "            meters.update(\"loss\", loss.item(), batch.y.shape[0])\n",
    "\n",
    "            pbar.set_description(f\"[Val(Batch)-- Idx: {idx + 1}| {desc} Loss : {meters['loss'].avg:.4f}]\")\n",
    "            pbar.update(1)\n",
    "            \n",
    "        rocauc = auc(targets_binary, np.array(preds_logit)[:, 1])\n",
    "        meters.update(\"roc_auc\", rocauc, len(targets_binary))\n",
    "        pbar.set_description(f\"[Val(Epoch)-- Idx: {idx + 1}| {desc} Loss : {meters['loss'].avg:.4f} | {desc} ROC-AUC : {meters['roc_auc'].avg:.4f}]\")\n",
    "       \n",
    "    metrics = evaluation_metrics(loss=meters[\"loss\"].avg, roc_auc=meters[\"roc_auc\"].avg)\n",
    "    return metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of FixMatch\n",
    "Fixmatch로 GINE를 학습하고, Best Validation 모델에 대해 Test Data ROC-AUC를 구하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_semi(model: nn.Module,\n",
    "            train_loader_labeled: DataLoader,\n",
    "            train_loader_unlabeled: DataLoader,\n",
    "            val_loader: DataLoader,\n",
    "            test_loader: DataLoader,\n",
    "            writer: SummaryWriter,\n",
    "            device: torch.device,\n",
    "            ema_decay: float,\n",
    "            epochs: int=100,\n",
    "            exp_id: int=1):\n",
    "      \n",
    "      model.to(device)\n",
    "      ema_model = EMA(model, ema_decay)\n",
    "      \n",
    "      optim_params = get_wd_param_list(model)      \n",
    "      optimizer = torch.optim.Adam(optim_params, lr=5e-4, weight_decay=1e-5)\n",
    "      scaler = GradScaler()\n",
    "      scheduler = CosineAnnealingLR(optimizer, T_max=90, eta_min=0, last_epoch=-1)\n",
    "      if not os.path.exists(f'./ckpt/EXP_{exp_id}'):\n",
    "            os.makedirs(f'./ckpt/EXP_{exp_id}')\n",
    "      best_val_cls = 0.\n",
    "      for ep in range(epochs):\n",
    "            print(f\"[Epoch : {ep:03d}]\")\n",
    "            train_total_loss, train_labeled_loss, train_unlabeled_loss = train_epoch_semi(model,\n",
    "                                                                                          ema_model,\n",
    "                                                                                          train_loader_labeled,\n",
    "                                                                                          train_loader_unlabeled,\n",
    "                                                                                          optimizer,\n",
    "                                                                                          scaler,\n",
    "                                                                                          device)\n",
    "            ema_model.assign(model)\n",
    "            val_metrics = evaluate(model, val_loader, device, \"Validation\")\n",
    "            writer.add_scalar(\"Loss/train_total\", train_total_loss, ep)\n",
    "            writer.add_scalar(\"Loss/train_labeled\", train_labeled_loss, ep)\n",
    "            writer.add_scalar(\"Loss/train_unlabeled\", train_unlabeled_loss, ep)\n",
    "            writer.add_scalar(\"Loss/val_total\", val_metrics.loss, ep)\n",
    "            writer.add_scalar(\"Classification_Metrics/auc\", val_metrics.roc_auc, ep)\n",
    "            ema_model.resume(model)\n",
    "            \n",
    "            if val_metrics.roc_auc > best_val_cls:\n",
    "                  best_val_cls = val_metrics.roc_auc\n",
    "                  torch.save(model.state_dict(), './ckpt/EXP_{exp_id}/best_model.ckpt')\n",
    "            \n",
    "            if ep > 10:\n",
    "                  scheduler.step()\n",
    "            \n",
    "      best_ckpt = torch.load(f'./ckpt/EXP_{exp_id}/best_model.ckpt')\n",
    "      model.load_state_dict(best_ckpt)\n",
    "      model.eval()\n",
    "      test_metrics = evaluate(model, test_loader, device, \"Test\")\n",
    "      return test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch : 000]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.7198 | Train(Labeled) Loss : 0.7007 | Train(Unlabeled) Loss : 0.006398660185942917: 100%|\u001b[96m██████████\u001b[39m| [00:15<00:00,  1.26it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6854 | Validation ROC-AUC : 0.6941]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.27it/s]\n",
      "[Epoch : 001]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6895 | Train(Labeled) Loss : 0.6883 | Train(Unlabeled) Loss : 0.00040891835171925396: 100%|\u001b[96m██████████\u001b[39m| [00:14<00:00,  1.28it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6839 | Validation ROC-AUC : 0.5481]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.28it/s]\n",
      "[Epoch : 002]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6822 | Train(Labeled) Loss : 0.6799 | Train(Unlabeled) Loss : 0.0007862005333759283: 100%|\u001b[96m██████████\u001b[39m| [00:14<00:00,  1.32it/s] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6849 | Validation ROC-AUC : 0.6193]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.54it/s]\n",
      "[Epoch : 003]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6822 | Train(Labeled) Loss : 0.6638 | Train(Unlabeled) Loss : 0.0059726833316840625: 100%|\u001b[96m██████████\u001b[39m| [00:14<00:00,  1.31it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6862 | Validation ROC-AUC : 0.5084]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 18.01it/s]\n",
      "[Epoch : 004]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.7498 | Train(Labeled) Loss : 0.6610 | Train(Unlabeled) Loss : 0.029543578134555566: 100%|\u001b[96m██████████\u001b[39m| [00:15<00:00,  1.26it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6850 | Validation ROC-AUC : 0.4643]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.74it/s]\n",
      "[Epoch : 005]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 1.0839 | Train(Labeled) Loss : 0.8562 | Train(Unlabeled) Loss : 0.076110990914075: 100%|\u001b[96m██████████\u001b[39m| [00:15<00:00,  1.25it/s]  \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6841 | Validation ROC-AUC : 0.4332]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.58it/s]\n",
      "[Epoch : 006]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.9538 | Train(Labeled) Loss : 0.7286 | Train(Unlabeled) Loss : 0.0750805430702473: 100%|\u001b[96m██████████\u001b[39m| [00:14<00:00,  1.32it/s] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6835 | Validation ROC-AUC : 0.4957]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.41it/s]\n",
      "[Epoch : 007]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.9810 | Train(Labeled) Loss : 0.6938 | Train(Unlabeled) Loss : 0.09573349513505634: 100%|\u001b[96m██████████\u001b[39m| [00:14<00:00,  1.35it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6834 | Validation ROC-AUC : 0.5710]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 17.14it/s]\n",
      "[Epoch : 008]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 1.2542 | Train(Labeled) Loss : 0.6891 | Train(Unlabeled) Loss : 0.18832082536659742: 100%|\u001b[96m██████████\u001b[39m| [00:14<00:00,  1.30it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6854 | Validation ROC-AUC : 0.4904]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.58it/s]\n",
      "[Epoch : 009]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 1.0742 | Train(Labeled) Loss : 0.7074 | Train(Unlabeled) Loss : 0.1222494556323478: 100%|\u001b[96m██████████\u001b[39m| [00:14<00:00,  1.32it/s] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6851 | Validation ROC-AUC : 0.4789]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.69it/s]\n",
      "[Epoch : 010]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.7859 | Train(Labeled) Loss : 0.6927 | Train(Unlabeled) Loss : 0.030906946447334792: 100%|\u001b[96m██████████\u001b[39m| [00:14<00:00,  1.34it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6892 | Validation ROC-AUC : 0.5674]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 22.39it/s]\n",
      "[Epoch : 011]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.7080 | Train(Labeled) Loss : 0.6997 | Train(Unlabeled) Loss : 0.002725755124916568: 100%|\u001b[96m██████████\u001b[39m| [00:13<00:00,  1.37it/s] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6973 | Validation ROC-AUC : 0.5360]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.13it/s]\n",
      "[Epoch : 012]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6867 | Train(Labeled) Loss : 0.6791 | Train(Unlabeled) Loss : 0.002446584302417346: 100%|\u001b[96m██████████\u001b[39m| [00:14<00:00,  1.33it/s] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7039 | Validation ROC-AUC : 0.5396]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.27it/s]\n",
      "[Epoch : 013]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6962 | Train(Labeled) Loss : 0.6872 | Train(Unlabeled) Loss : 0.002890086815520925: 100%|\u001b[96m██████████\u001b[39m| [00:15<00:00,  1.26it/s] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7088 | Validation ROC-AUC : 0.5356]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 25.42it/s]\n",
      "[Epoch : 014]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6879 | Train(Labeled) Loss : 0.6826 | Train(Unlabeled) Loss : 0.001834846809383874: 100%|\u001b[96m██████████\u001b[39m| [00:24<00:00,  1.28s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7204 | Validation ROC-AUC : 0.5305]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.30it/s]\n",
      "[Epoch : 015]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6898 | Train(Labeled) Loss : 0.6845 | Train(Unlabeled) Loss : 0.0015748657200387434: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.72s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7314 | Validation ROC-AUC : 0.5423]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.50it/s]\n",
      "[Epoch : 016]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6814 | Train(Labeled) Loss : 0.6765 | Train(Unlabeled) Loss : 0.0017139797870952048: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7479 | Validation ROC-AUC : 0.5465]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.95it/s]\n",
      "[Epoch : 017]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6860 | Train(Labeled) Loss : 0.6698 | Train(Unlabeled) Loss : 0.0052544604374193836: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7599 | Validation ROC-AUC : 0.5720]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.39it/s]\n",
      "[Epoch : 018]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6744 | Train(Labeled) Loss : 0.6556 | Train(Unlabeled) Loss : 0.006392990530002862: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7824 | Validation ROC-AUC : 0.5705]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.41it/s]\n",
      "[Epoch : 019]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6667 | Train(Labeled) Loss : 0.6553 | Train(Unlabeled) Loss : 0.0038604966462834887: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7936 | Validation ROC-AUC : 0.5955]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.00it/s]\n",
      "[Epoch : 020]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6633 | Train(Labeled) Loss : 0.6566 | Train(Unlabeled) Loss : 0.0022115785426362173: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.65s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7946 | Validation ROC-AUC : 0.5960]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.05it/s]\n",
      "[Epoch : 021]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6535 | Train(Labeled) Loss : 0.6405 | Train(Unlabeled) Loss : 0.004356447916698495: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.8278 | Validation ROC-AUC : 0.6061]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.97it/s]\n",
      "[Epoch : 022]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6697 | Train(Labeled) Loss : 0.6636 | Train(Unlabeled) Loss : 0.002129066404641459: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.8411 | Validation ROC-AUC : 0.6089]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.72it/s]\n",
      "[Epoch : 023]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6361 | Train(Labeled) Loss : 0.6264 | Train(Unlabeled) Loss : 0.0032474892122033787: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.8951 | Validation ROC-AUC : 0.6064]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.24it/s]\n",
      "[Epoch : 024]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6346 | Train(Labeled) Loss : 0.6183 | Train(Unlabeled) Loss : 0.00549903020299481: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it]  \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.9139 | Validation ROC-AUC : 0.5986]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.04it/s]\n",
      "[Epoch : 025]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 1.0133 | Train(Labeled) Loss : 0.7226 | Train(Unlabeled) Loss : 0.0968858997680639: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7497 | Validation ROC-AUC : 0.6137]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.61it/s]\n",
      "[Epoch : 026]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.7371 | Train(Labeled) Loss : 0.6809 | Train(Unlabeled) Loss : 0.01877313719964341: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.64s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7436 | Validation ROC-AUC : 0.6424]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.24it/s]\n",
      "[Epoch : 027]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6793 | Train(Labeled) Loss : 0.6720 | Train(Unlabeled) Loss : 0.002379611382677563: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.8107 | Validation ROC-AUC : 0.5933]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.52it/s]\n",
      "[Epoch : 028]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6731 | Train(Labeled) Loss : 0.6662 | Train(Unlabeled) Loss : 0.0023858260155018222: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.8636 | Validation ROC-AUC : 0.5953]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.72it/s]\n",
      "[Epoch : 029]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6829 | Train(Labeled) Loss : 0.6715 | Train(Unlabeled) Loss : 0.0038967944534593507: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.9315 | Validation ROC-AUC : 0.5592]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.69it/s]\n",
      "[Epoch : 030]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6621 | Train(Labeled) Loss : 0.6472 | Train(Unlabeled) Loss : 0.005012732967244167: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.65s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.9950 | Validation ROC-AUC : 0.5723]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 10.79it/s]\n",
      "[Epoch : 031]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6545 | Train(Labeled) Loss : 0.6410 | Train(Unlabeled) Loss : 0.004758041741105875: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.0548 | Validation ROC-AUC : 0.5716]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.58it/s]\n",
      "[Epoch : 032]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6573 | Train(Labeled) Loss : 0.6474 | Train(Unlabeled) Loss : 0.0033638344489430125: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.1127 | Validation ROC-AUC : 0.5640]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.84it/s]\n",
      "[Epoch : 033]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6529 | Train(Labeled) Loss : 0.6446 | Train(Unlabeled) Loss : 0.002838757890889323: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.1516 | Validation ROC-AUC : 0.5966]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.24it/s]\n",
      "[Epoch : 034]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6325 | Train(Labeled) Loss : 0.6231 | Train(Unlabeled) Loss : 0.0030853166183652846: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.2383 | Validation ROC-AUC : 0.6206]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.54it/s]\n",
      "[Epoch : 035]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6389 | Train(Labeled) Loss : 0.6303 | Train(Unlabeled) Loss : 0.0027404233099476093: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.3272 | Validation ROC-AUC : 0.6170]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.07it/s]\n",
      "[Epoch : 036]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6492 | Train(Labeled) Loss : 0.6171 | Train(Unlabeled) Loss : 0.010779552903075359: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.3358 | Validation ROC-AUC : 0.5966]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.36it/s]\n",
      "[Epoch : 037]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.7259 | Train(Labeled) Loss : 0.6430 | Train(Unlabeled) Loss : 0.027602258873613256: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.4796 | Validation ROC-AUC : 0.6197]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.32it/s]\n",
      "[Epoch : 038]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6484 | Train(Labeled) Loss : 0.6365 | Train(Unlabeled) Loss : 0.0039187920399279775: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.6461 | Validation ROC-AUC : 0.6098]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.07it/s]\n",
      "[Epoch : 039]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6409 | Train(Labeled) Loss : 0.6340 | Train(Unlabeled) Loss : 0.0023236231002221374: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.7173 | Validation ROC-AUC : 0.6190]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.67it/s]\n",
      "[Epoch : 040]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6162 | Train(Labeled) Loss : 0.6093 | Train(Unlabeled) Loss : 0.0024924736476111178: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.70s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.8061 | Validation ROC-AUC : 0.6068]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.11it/s]\n",
      "[Epoch : 041]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6290 | Train(Labeled) Loss : 0.6226 | Train(Unlabeled) Loss : 0.0020470300238996154: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.7381 | Validation ROC-AUC : 0.6038]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.67it/s]\n",
      "[Epoch : 042]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6058 | Train(Labeled) Loss : 0.6010 | Train(Unlabeled) Loss : 0.0015853090000363362: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.8547 | Validation ROC-AUC : 0.5970]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.03it/s]\n",
      "[Epoch : 043]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6245 | Train(Labeled) Loss : 0.5850 | Train(Unlabeled) Loss : 0.013277237305086792: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.8948 | Validation ROC-AUC : 0.6020]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.63it/s]\n",
      "[Epoch : 044]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 1.1634 | Train(Labeled) Loss : 0.6403 | Train(Unlabeled) Loss : 0.1743871138284081: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.5661 | Validation ROC-AUC : 0.5948]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.86it/s]\n",
      "[Epoch : 045]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 1.0993 | Train(Labeled) Loss : 0.6899 | Train(Unlabeled) Loss : 0.1364874692731782: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.69s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.3851 | Validation ROC-AUC : 0.4698]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.72it/s]\n",
      "[Epoch : 046]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.7471 | Train(Labeled) Loss : 0.7203 | Train(Unlabeled) Loss : 0.009049508941212767: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.8643 | Validation ROC-AUC : 0.5002]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.09it/s]\n",
      "[Epoch : 047]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6954 | Train(Labeled) Loss : 0.6847 | Train(Unlabeled) Loss : 0.0035846467454623628: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.0651 | Validation ROC-AUC : 0.4857]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 10.95it/s]\n",
      "[Epoch : 048]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6842 | Train(Labeled) Loss : 0.6780 | Train(Unlabeled) Loss : 0.0020568612717876307: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.1584 | Validation ROC-AUC : 0.4750]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.76it/s]\n",
      "[Epoch : 049]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6842 | Train(Labeled) Loss : 0.6802 | Train(Unlabeled) Loss : 0.0013799951319876862: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.2206 | Validation ROC-AUC : 0.4703]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.00it/s]\n",
      "[Epoch : 050]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6692 | Train(Labeled) Loss : 0.6653 | Train(Unlabeled) Loss : 0.001239875686894122: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.2433 | Validation ROC-AUC : 0.4682]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.81it/s]\n",
      "[Epoch : 051]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6674 | Train(Labeled) Loss : 0.6640 | Train(Unlabeled) Loss : 0.001100875829395495: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.2482 | Validation ROC-AUC : 0.4694]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.00it/s]\n",
      "[Epoch : 052]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6696 | Train(Labeled) Loss : 0.6653 | Train(Unlabeled) Loss : 0.0013854189922935085: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.2420 | Validation ROC-AUC : 0.4694]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  8.79it/s]\n",
      "[Epoch : 053]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6521 | Train(Labeled) Loss : 0.6487 | Train(Unlabeled) Loss : 0.0011059673806333816: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.69s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.2370 | Validation ROC-AUC : 0.4719]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.24it/s]\n",
      "[Epoch : 054]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6423 | Train(Labeled) Loss : 0.6390 | Train(Unlabeled) Loss : 0.0011545439070017125: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.69s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.3078 | Validation ROC-AUC : 0.4748]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.63it/s]\n",
      "[Epoch : 055]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6315 | Train(Labeled) Loss : 0.6282 | Train(Unlabeled) Loss : 0.0010774463804218133: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.69s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.3054 | Validation ROC-AUC : 0.4758]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.38it/s]\n",
      "[Epoch : 056]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6209 | Train(Labeled) Loss : 0.6168 | Train(Unlabeled) Loss : 0.0011663083063659112: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.2917 | Validation ROC-AUC : 0.4794]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.41it/s]\n",
      "[Epoch : 057]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6037 | Train(Labeled) Loss : 0.5999 | Train(Unlabeled) Loss : 0.0014080643304623663: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.70s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.2036 | Validation ROC-AUC : 0.4794]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.05it/s]\n",
      "[Epoch : 058]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6047 | Train(Labeled) Loss : 0.5999 | Train(Unlabeled) Loss : 0.0015387316295681032: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.2619 | Validation ROC-AUC : 0.4789]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.36it/s]\n",
      "[Epoch : 059]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5826 | Train(Labeled) Loss : 0.5744 | Train(Unlabeled) Loss : 0.002965372300853855: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.69s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.2425 | Validation ROC-AUC : 0.4785]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.72it/s]\n",
      "[Epoch : 060]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6052 | Train(Labeled) Loss : 0.5865 | Train(Unlabeled) Loss : 0.006247245718872077: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.3367 | Validation ROC-AUC : 0.4807]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.67it/s]\n",
      "[Epoch : 061]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.6038 | Train(Labeled) Loss : 0.5924 | Train(Unlabeled) Loss : 0.003826856597841374: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.70s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.4698 | Validation ROC-AUC : 0.4812]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.86it/s]\n",
      "[Epoch : 062]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5773 | Train(Labeled) Loss : 0.5728 | Train(Unlabeled) Loss : 0.0014127850238429872: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.69s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.5053 | Validation ROC-AUC : 0.4805]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 10.95it/s]\n",
      "[Epoch : 063]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5617 | Train(Labeled) Loss : 0.5580 | Train(Unlabeled) Loss : 0.0013499383716598938: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.69s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.4415 | Validation ROC-AUC : 0.4782]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.76it/s]\n",
      "[Epoch : 064]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5606 | Train(Labeled) Loss : 0.5520 | Train(Unlabeled) Loss : 0.0029884707986830585: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.69s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.5398 | Validation ROC-AUC : 0.4809]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.63it/s]\n",
      "[Epoch : 065]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5638 | Train(Labeled) Loss : 0.5602 | Train(Unlabeled) Loss : 0.0011837281835093898: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.5985 | Validation ROC-AUC : 0.4814]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.67it/s]\n",
      "[Epoch : 066]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5533 | Train(Labeled) Loss : 0.5470 | Train(Unlabeled) Loss : 0.0020309504141455123: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.69s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.5550 | Validation ROC-AUC : 0.4816]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.41it/s]\n",
      "[Epoch : 067]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5568 | Train(Labeled) Loss : 0.5498 | Train(Unlabeled) Loss : 0.002053460501453006: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.6494 | Validation ROC-AUC : 0.4818]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 10.83it/s]\n",
      "[Epoch : 068]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5509 | Train(Labeled) Loss : 0.5466 | Train(Unlabeled) Loss : 0.0013467277527333384: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.5734 | Validation ROC-AUC : 0.4816]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 10.87it/s]\n",
      "[Epoch : 069]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5420 | Train(Labeled) Loss : 0.5374 | Train(Unlabeled) Loss : 0.0018000488213912927: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.7074 | Validation ROC-AUC : 0.4832]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.49it/s]\n",
      "[Epoch : 070]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5425 | Train(Labeled) Loss : 0.5316 | Train(Unlabeled) Loss : 0.0036722479761872244: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.70s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.6978 | Validation ROC-AUC : 0.4855]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.20it/s]\n",
      "[Epoch : 071]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5424 | Train(Labeled) Loss : 0.5351 | Train(Unlabeled) Loss : 0.0021167337208202013: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.6517 | Validation ROC-AUC : 0.4862]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.81it/s]\n",
      "[Epoch : 072]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5464 | Train(Labeled) Loss : 0.5332 | Train(Unlabeled) Loss : 0.004545602353142672: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.8740 | Validation ROC-AUC : 0.4869]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 10.60it/s]\n",
      "[Epoch : 073]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5473 | Train(Labeled) Loss : 0.5201 | Train(Unlabeled) Loss : 0.00898774046034209: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.9439 | Validation ROC-AUC : 0.4903]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.24it/s]\n",
      "[Epoch : 074]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5519 | Train(Labeled) Loss : 0.5195 | Train(Unlabeled) Loss : 0.010847200017643013: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 2.9387 | Validation ROC-AUC : 0.4916]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.81it/s]\n",
      "[Epoch : 075]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5462 | Train(Labeled) Loss : 0.5339 | Train(Unlabeled) Loss : 0.004069215245851267: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 3.0112 | Validation ROC-AUC : 0.4907]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.63it/s]\n",
      "[Epoch : 076]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5264 | Train(Labeled) Loss : 0.5117 | Train(Unlabeled) Loss : 0.004810601262234789: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 3.1487 | Validation ROC-AUC : 0.4907]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.90it/s]\n",
      "[Epoch : 077]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5239 | Train(Labeled) Loss : 0.5114 | Train(Unlabeled) Loss : 0.004175593567963101: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 3.3914 | Validation ROC-AUC : 0.4932]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.63it/s]\n",
      "[Epoch : 078]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5299 | Train(Labeled) Loss : 0.5111 | Train(Unlabeled) Loss : 0.006224217071001859: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 3.6116 | Validation ROC-AUC : 0.4934]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.49it/s]\n",
      "[Epoch : 079]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5374 | Train(Labeled) Loss : 0.5195 | Train(Unlabeled) Loss : 0.006013586925722561: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 3.4101 | Validation ROC-AUC : 0.4925]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.49it/s]\n",
      "[Epoch : 080]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5138 | Train(Labeled) Loss : 0.5009 | Train(Unlabeled) Loss : 0.004148913222659183: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 3.5122 | Validation ROC-AUC : 0.4941]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 10.38it/s]\n",
      "[Epoch : 081]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5251 | Train(Labeled) Loss : 0.5058 | Train(Unlabeled) Loss : 0.006508105121994097: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 3.6174 | Validation ROC-AUC : 0.4941]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 10.87it/s]\n",
      "[Epoch : 082]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5148 | Train(Labeled) Loss : 0.5075 | Train(Unlabeled) Loss : 0.0024617052909697555: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 3.7415 | Validation ROC-AUC : 0.4939]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.67it/s]\n",
      "[Epoch : 083]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5131 | Train(Labeled) Loss : 0.5029 | Train(Unlabeled) Loss : 0.003361832819217326: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 3.8667 | Validation ROC-AUC : 0.4950]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.63it/s]\n",
      "[Epoch : 084]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5262 | Train(Labeled) Loss : 0.5181 | Train(Unlabeled) Loss : 0.0026651961425637923: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.65s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 3.9506 | Validation ROC-AUC : 0.4950]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.50it/s]\n",
      "[Epoch : 085]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5193 | Train(Labeled) Loss : 0.5098 | Train(Unlabeled) Loss : 0.003040238954494462: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 3.9506 | Validation ROC-AUC : 0.4955]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.90it/s]\n",
      "[Epoch : 086]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5062 | Train(Labeled) Loss : 0.4961 | Train(Unlabeled) Loss : 0.0032884600177088656: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 3.9967 | Validation ROC-AUC : 0.4952]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.72it/s]\n",
      "[Epoch : 087]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5207 | Train(Labeled) Loss : 0.5052 | Train(Unlabeled) Loss : 0.005271068863772885: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.70s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 4.1495 | Validation ROC-AUC : 0.4980]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.95it/s]\n",
      "[Epoch : 088]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5217 | Train(Labeled) Loss : 0.5108 | Train(Unlabeled) Loss : 0.0035342762972791924: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 4.1446 | Validation ROC-AUC : 0.4971]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.95it/s]\n",
      "[Epoch : 089]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5085 | Train(Labeled) Loss : 0.4980 | Train(Unlabeled) Loss : 0.0034139065943523555: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 4.2012 | Validation ROC-AUC : 0.5002]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.15it/s]\n",
      "[Epoch : 090]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5195 | Train(Labeled) Loss : 0.5015 | Train(Unlabeled) Loss : 0.005750433895675661: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 4.2387 | Validation ROC-AUC : 0.5014]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.05it/s]\n",
      "[Epoch : 091]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5234 | Train(Labeled) Loss : 0.5111 | Train(Unlabeled) Loss : 0.00391900065158935: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it]  \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 4.3014 | Validation ROC-AUC : 0.5045]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.63it/s]\n",
      "[Epoch : 092]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5020 | Train(Labeled) Loss : 0.4920 | Train(Unlabeled) Loss : 0.0033272173359843067: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 4.3956 | Validation ROC-AUC : 0.5045]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.58it/s]\n",
      "[Epoch : 093]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5042 | Train(Labeled) Loss : 0.4931 | Train(Unlabeled) Loss : 0.0037410792597496: 100%|\u001b[96m██████████\u001b[39m| [00:32<00:00,  1.69s/it]   \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 4.4674 | Validation ROC-AUC : 0.5073]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.00it/s]\n",
      "[Epoch : 094]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5140 | Train(Labeled) Loss : 0.5005 | Train(Unlabeled) Loss : 0.004612060170314324: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.65s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 4.5058 | Validation ROC-AUC : 0.5114]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.19it/s]\n",
      "[Epoch : 095]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5104 | Train(Labeled) Loss : 0.5024 | Train(Unlabeled) Loss : 0.002700141628003238: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 4.5507 | Validation ROC-AUC : 0.5157]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 10.72it/s]\n",
      "[Epoch : 096]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5094 | Train(Labeled) Loss : 0.5015 | Train(Unlabeled) Loss : 0.002711846202146262: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.68s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 4.6157 | Validation ROC-AUC : 0.5190]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 10.91it/s]\n",
      "[Epoch : 097]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5054 | Train(Labeled) Loss : 0.4932 | Train(Unlabeled) Loss : 0.004210050214743732: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 4.6444 | Validation ROC-AUC : 0.5231]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.15it/s]\n",
      "[Epoch : 098]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5119 | Train(Labeled) Loss : 0.4966 | Train(Unlabeled) Loss : 0.004922017926889423: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.67s/it] \n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 4.6893 | Validation ROC-AUC : 0.5301]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.95it/s]\n",
      "[Epoch : 099]\n",
      "[Train(Epoch)-- Idx: 19| Train(Total) Loss : 0.5085 | Train(Labeled) Loss : 0.4968 | Train(Unlabeled) Loss : 0.0038702607883973734: 100%|\u001b[96m██████████\u001b[39m| [00:31<00:00,  1.66s/it]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 4.7197 | Validation ROC-AUC : 0.5345]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 12.10it/s]\n",
      "[Val(Epoch)-- Idx: 3| Test Loss : 0.4227 | Test ROC-AUC : 0.8720]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.50it/s]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('./runs/EXP_1')\n",
    "test_metrics = run_semi(model, train_loader_labeled, train_loader_unlabeled, val_loader, test_loader, writer, device, ema_decay=0.999, epochs=EPOCHS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터 성능 결과 ROC-AUC가 0.8720을 기록하였습니다. Fixmatch의 효과를 입증하기 위해서는 Unlabeled Data를 사용하지 않은 순수 지도학습의 결과가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performance : ROC-AUC 0.8720\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Performance : ROC-AUC {test_metrics.roc_auc:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Trainer(Supervised Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_step(model: nn.Module,\n",
    "                batch: Batch,\n",
    "                meters: AverageMeterSet,\n",
    "                device:torch.device):\n",
    "    \n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    _, pred = model(batch)\n",
    "    \n",
    "    labeled_loss = F.cross_entropy(pred, batch.y.reshape(-1), reduction='mean')\n",
    "    \n",
    "    meters.update(\"labeled_loss\", labeled_loss.mean().item(), pred.shape[0])\n",
    "    \n",
    "    return labeled_loss\n",
    "\n",
    "def train_epoch(model: nn.Module,\n",
    "                train_loader_labeled: DataLoader,\n",
    "                optimizer: torch.optim.Adam,\n",
    "                scaler: GradScaler,\n",
    "                device: torch.device):\n",
    "    \n",
    "    meters = AverageMeterSet()\n",
    "    \n",
    "    model.train()\n",
    "    with tqdm(**get_tqdm_config(total=len(train_loader_labeled), leave=True, color='cyan')) as pbar:\n",
    "        for idx, batch in enumerate(train_loader_labeled):\n",
    "            with autocast():\n",
    "                loss = _train_step(model, batch, meters, device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            pbar.set_description(f\"[Train(Batch)-- Idx: {idx + 1}| Train(Labeled) Loss : {meters['labeled_loss'].avg:.4f}\")\n",
    "            pbar.update(1)\n",
    "        pbar.set_description(f\"[Train(Epoch)-- Idx: {idx + 1}| Train(Labeled) Loss : {meters['labeled_loss'].avg:.4f}\")\n",
    "    \n",
    "    return meters['labeled_loss'].avg\n",
    "\n",
    "def run(model: nn.Module,\n",
    "        train_loader_labeled: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        test_loader: DataLoader,\n",
    "        writer: SummaryWriter,\n",
    "        device: torch.device,\n",
    "        epochs: int=100,\n",
    "        exp_id: int=1):\n",
    "    \n",
    "    model.to(device)\n",
    "      \n",
    "    optim_params = get_wd_param_list(model)      \n",
    "    optimizer = torch.optim.Adam(optim_params, lr=5e-4, weight_decay=1e-5)\n",
    "    scaler = GradScaler()\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=90, eta_min=0, last_epoch=-1)\n",
    "    if not os.path.exists(f'./ckpt/EXP_{exp_id}'):\n",
    "        os.makedirs(f'./ckpt/EXP_{exp_id}')\n",
    "        \n",
    "    best_val_cls = 0.\n",
    "    for ep in range(epochs):\n",
    "        print(f\"[Epoch : {ep:03d}]\")\n",
    "        train_labeled_loss = train_epoch(model,\n",
    "                                         train_loader_labeled,\n",
    "                                         optimizer,\n",
    "                                         scaler,\n",
    "                                         device)\n",
    "        val_metrics = evaluate(model, val_loader, device, \"Validation\")\n",
    "        writer.add_scalar(\"Loss/train_labeled\", train_labeled_loss, ep)\n",
    "        writer.add_scalar(\"Loss/val_total\", val_metrics.loss, ep)\n",
    "        writer.add_scalar(\"Classification_Metrics/auc\", val_metrics.roc_auc, ep)\n",
    "\n",
    "        if val_metrics.roc_auc > best_val_cls:\n",
    "            best_val_cls = val_metrics.roc_auc\n",
    "            torch.save(model.state_dict(), f'./ckpt/EXP_{exp_id}/best_model.ckpt')\n",
    "            \n",
    "            if ep > 10:\n",
    "                scheduler.step()\n",
    "            \n",
    "    best_ckpt = torch.load(f'./ckpt/EXP_{exp_id}/best_model.ckpt')\n",
    "    model.load_state_dict(best_ckpt)\n",
    "    model.eval()\n",
    "    test_metrics = evaluate(model, test_loader, device, \"Test\")\n",
    "    return test_metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch : 000]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.6837: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.66it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6965 | Validation ROC-AUC : 0.5259]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.28it/s]\n",
      "[Epoch : 001]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.6301: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.93it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6486 | Validation ROC-AUC : 0.6889]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 18.99it/s]\n",
      "[Epoch : 002]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.5969: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.64it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5385 | Validation ROC-AUC : 0.8682]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.69it/s]\n",
      "[Epoch : 003]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.5928: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.11it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6291 | Validation ROC-AUC : 0.7753]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 17.75it/s]\n",
      "[Epoch : 004]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.5780: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.99it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.1641 | Validation ROC-AUC : 0.6835]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.83it/s]\n",
      "[Epoch : 005]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.5558: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.31it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5122 | Validation ROC-AUC : 0.8456]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 19.74it/s]\n",
      "[Epoch : 006]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.5608: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.71it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5509 | Validation ROC-AUC : 0.8174]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.98it/s]\n",
      "[Epoch : 007]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.5411: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.51it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.2805 | Validation ROC-AUC : 0.6311]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.83it/s]\n",
      "[Epoch : 008]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.5366: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.23it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5504 | Validation ROC-AUC : 0.7882]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.74it/s]\n",
      "[Epoch : 009]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.5260: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.95it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.8523 | Validation ROC-AUC : 0.6968]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 18.87it/s]\n",
      "[Epoch : 010]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.5538: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.79it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.8777 | Validation ROC-AUC : 0.7792]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.83it/s]\n",
      "[Epoch : 011]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.5224: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.54it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5076 | Validation ROC-AUC : 0.8313]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.13it/s]\n",
      "[Epoch : 012]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.5140: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.82it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5079 | Validation ROC-AUC : 0.8326]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.43it/s]\n",
      "[Epoch : 013]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4867: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.06it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6255 | Validation ROC-AUC : 0.8059]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 18.75it/s]\n",
      "[Epoch : 014]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4899: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.81it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7217 | Validation ROC-AUC : 0.7522]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.74it/s]\n",
      "[Epoch : 015]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.5044: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.69it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6305 | Validation ROC-AUC : 0.7197]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.98it/s]\n",
      "[Epoch : 016]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4902: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.74it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5007 | Validation ROC-AUC : 0.8347]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.28it/s]\n",
      "[Epoch : 017]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4930: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.75it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6443 | Validation ROC-AUC : 0.7660]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.58it/s]\n",
      "[Epoch : 018]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4602: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.31it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6791 | Validation ROC-AUC : 0.7791]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 18.41it/s]\n",
      "[Epoch : 019]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4789: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.27it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5763 | Validation ROC-AUC : 0.8580]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 19.11it/s]\n",
      "[Epoch : 020]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4675: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.19it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6051 | Validation ROC-AUC : 0.8156]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.83it/s]\n",
      "[Epoch : 021]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4532: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.42it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7898 | Validation ROC-AUC : 0.8088]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.69it/s]\n",
      "[Epoch : 022]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4644: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.63it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6380 | Validation ROC-AUC : 0.7526]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.28it/s]\n",
      "[Epoch : 023]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4664: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.18it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5990 | Validation ROC-AUC : 0.8320]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.43it/s]\n",
      "[Epoch : 024]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4578: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.22it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5217 | Validation ROC-AUC : 0.8424]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.41it/s]\n",
      "[Epoch : 025]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4529: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.59it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4763 | Validation ROC-AUC : 0.8519]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.83it/s]\n",
      "[Epoch : 026]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4400: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.42it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6374 | Validation ROC-AUC : 0.8020]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.69it/s]\n",
      "[Epoch : 027]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4667: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.17it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.5885 | Validation ROC-AUC : 0.8195]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.83it/s]\n",
      "[Epoch : 028]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4529: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.54it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6462 | Validation ROC-AUC : 0.8097]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 16.57it/s]\n",
      "[Epoch : 029]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4470: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.66it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7984 | Validation ROC-AUC : 0.7785]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.55it/s]\n",
      "[Epoch : 030]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4491: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.16it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4429 | Validation ROC-AUC : 0.8776]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.69it/s]\n",
      "[Epoch : 031]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4235: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.59it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6221 | Validation ROC-AUC : 0.7107]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.55it/s]\n",
      "[Epoch : 032]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4334: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.22it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5691 | Validation ROC-AUC : 0.8297]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.69it/s]\n",
      "[Epoch : 033]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4338: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.48it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5597 | Validation ROC-AUC : 0.8268]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.13it/s]\n",
      "[Epoch : 034]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4165: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.06it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4702 | Validation ROC-AUC : 0.8739]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 18.99it/s]\n",
      "[Epoch : 035]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4263: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.52it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.8098 | Validation ROC-AUC : 0.7456]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.28it/s]\n",
      "[Epoch : 036]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4348: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.44it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4914 | Validation ROC-AUC : 0.8428]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.13it/s]\n",
      "[Epoch : 037]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4041: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.71it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6290 | Validation ROC-AUC : 0.7855]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.69it/s]\n",
      "[Epoch : 038]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4090: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.40it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.8706 | Validation ROC-AUC : 0.8322]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.43it/s]\n",
      "[Epoch : 039]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4089: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.37it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6059 | Validation ROC-AUC : 0.8165]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 19.23it/s]\n",
      "[Epoch : 040]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4033: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.93it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5888 | Validation ROC-AUC : 0.8154]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.13it/s]\n",
      "[Epoch : 041]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4088: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.70it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6319 | Validation ROC-AUC : 0.8517]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.00it/s]\n",
      "[Epoch : 042]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4063: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.22it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6886 | Validation ROC-AUC : 0.7946]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 18.23it/s]\n",
      "[Epoch : 043]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4074: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.40it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.8867 | Validation ROC-AUC : 0.8174]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 22.56it/s]\n",
      "[Epoch : 044]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4056: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 13.19it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7175 | Validation ROC-AUC : 0.6462]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 23.08it/s]\n",
      "[Epoch : 045]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4059: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.79it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4489 | Validation ROC-AUC : 0.8750]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 22.06it/s]\n",
      "[Epoch : 046]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3995: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.47it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5082 | Validation ROC-AUC : 0.8521]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.58it/s]\n",
      "[Epoch : 047]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.4011: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.83it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5850 | Validation ROC-AUC : 0.7971]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.55it/s]\n",
      "[Epoch : 048]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3923: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.25it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5510 | Validation ROC-AUC : 0.8628]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.41it/s]\n",
      "[Epoch : 049]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3915: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.36it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4717 | Validation ROC-AUC : 0.8737]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.13it/s]\n",
      "[Epoch : 050]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3817: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.47it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5707 | Validation ROC-AUC : 0.7987]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 21.43it/s]\n",
      "[Epoch : 051]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3711: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.80it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7434 | Validation ROC-AUC : 0.7921]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.41it/s]\n",
      "[Epoch : 052]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3726: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 11.83it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5051 | Validation ROC-AUC : 0.8723]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 20.13it/s]\n",
      "[Epoch : 053]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3987: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.96it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5099 | Validation ROC-AUC : 0.8501]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 18.87it/s]\n",
      "[Epoch : 054]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3669: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 12.39it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5800 | Validation ROC-AUC : 0.8762]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 19.87it/s]\n",
      "[Epoch : 055]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3836: 100%|\u001b[96m██████████\u001b[39m| [00:01<00:00, 10.12it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4968 | Validation ROC-AUC : 0.8723]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.74it/s]\n",
      "[Epoch : 056]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3723: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.73it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.0448 | Validation ROC-AUC : 0.6367]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.38it/s]\n",
      "[Epoch : 057]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3692: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  7.12it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.0967 | Validation ROC-AUC : 0.8279]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 10.07it/s]\n",
      "[Epoch : 058]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3973: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.78it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5515 | Validation ROC-AUC : 0.8200]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.32it/s]\n",
      "[Epoch : 059]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3863: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  6.64it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4789 | Validation ROC-AUC : 0.8599]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.15it/s]\n",
      "[Epoch : 060]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3573: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  7.05it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4704 | Validation ROC-AUC : 0.8853]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.15it/s]\n",
      "[Epoch : 061]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3619: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.57it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5253 | Validation ROC-AUC : 0.8327]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.43it/s]\n",
      "[Epoch : 062]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3511: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  6.53it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5396 | Validation ROC-AUC : 0.8487]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 10.56it/s]\n",
      "[Epoch : 063]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3672: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  6.02it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4947 | Validation ROC-AUC : 0.8528]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.34it/s]\n",
      "[Epoch : 064]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3751: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.68it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4928 | Validation ROC-AUC : 0.8708]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.65it/s]\n",
      "[Epoch : 065]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3572: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  6.91it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4921 | Validation ROC-AUC : 0.8571]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.43it/s]\n",
      "[Epoch : 066]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3571: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.89it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4912 | Validation ROC-AUC : 0.8671]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.01it/s]\n",
      "[Epoch : 067]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3586: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  6.73it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4740 | Validation ROC-AUC : 0.8778]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  8.61it/s]\n",
      "[Epoch : 068]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3643: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  6.01it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5129 | Validation ROC-AUC : 0.8322]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  8.96it/s]\n",
      "[Epoch : 069]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3374: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.86it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4898 | Validation ROC-AUC : 0.8809]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.68it/s]\n",
      "[Epoch : 070]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3302: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  6.84it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 1.2593 | Validation ROC-AUC : 0.6716]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  8.80it/s]\n",
      "[Epoch : 071]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3320: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.65it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6333 | Validation ROC-AUC : 0.8778]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.52it/s]\n",
      "[Epoch : 072]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3603: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  6.69it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5539 | Validation ROC-AUC : 0.8472]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.63it/s]\n",
      "[Epoch : 073]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3349: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.90it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5817 | Validation ROC-AUC : 0.8161]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.74it/s]\n",
      "[Epoch : 074]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3409: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.93it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5213 | Validation ROC-AUC : 0.8619]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.36it/s]\n",
      "[Epoch : 075]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3406: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  6.94it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5090 | Validation ROC-AUC : 0.8775]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.62it/s]\n",
      "[Epoch : 076]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3080: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  6.55it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5558 | Validation ROC-AUC : 0.8449]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.49it/s]\n",
      "[Epoch : 077]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3260: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.72it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7373 | Validation ROC-AUC : 0.7839]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.12it/s]\n",
      "[Epoch : 078]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3473: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.88it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5613 | Validation ROC-AUC : 0.8420]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.50it/s]\n",
      "[Epoch : 079]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3343: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  6.41it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5578 | Validation ROC-AUC : 0.8424]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.49it/s]\n",
      "[Epoch : 080]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3302: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  6.45it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6706 | Validation ROC-AUC : 0.8372]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.54it/s]\n",
      "[Epoch : 081]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3193: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.80it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.7925 | Validation ROC-AUC : 0.8487]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.49it/s]\n",
      "[Epoch : 082]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3308: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.82it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5116 | Validation ROC-AUC : 0.8537]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.06it/s]\n",
      "[Epoch : 083]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3307: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  6.79it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6204 | Validation ROC-AUC : 0.8422]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  8.80it/s]\n",
      "[Epoch : 084]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3162: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.76it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5784 | Validation ROC-AUC : 0.8089]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  8.96it/s]\n",
      "[Epoch : 085]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3049: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  6.30it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6711 | Validation ROC-AUC : 0.7900]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.85it/s]\n",
      "[Epoch : 086]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3124: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  6.15it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4672 | Validation ROC-AUC : 0.8993]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.37it/s]\n",
      "[Epoch : 087]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.2987: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  6.21it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5458 | Validation ROC-AUC : 0.8886]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 10.68it/s]\n",
      "[Epoch : 088]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3255: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  7.11it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5292 | Validation ROC-AUC : 0.8848]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.36it/s]\n",
      "[Epoch : 089]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3343: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  7.52it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4295 | Validation ROC-AUC : 0.8893]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.45it/s]\n",
      "[Epoch : 090]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3158: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.94it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5210 | Validation ROC-AUC : 0.8655]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.32it/s]\n",
      "[Epoch : 091]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3236: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.81it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.8000 | Validation ROC-AUC : 0.7499]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.35it/s]\n",
      "[Epoch : 092]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3131: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  6.71it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.6412 | Validation ROC-AUC : 0.8599]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.11it/s]\n",
      "[Epoch : 093]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3129: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.82it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4803 | Validation ROC-AUC : 0.8687]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.35it/s]\n",
      "[Epoch : 094]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3124: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.76it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5421 | Validation ROC-AUC : 0.8436]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.15it/s]\n",
      "[Epoch : 095]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3027: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.89it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4984 | Validation ROC-AUC : 0.8826]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.17it/s]\n",
      "[Epoch : 096]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.2770: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  6.76it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5454 | Validation ROC-AUC : 0.8728]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  8.26it/s]\n",
      "[Epoch : 097]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.2952: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.69it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5030 | Validation ROC-AUC : 0.8655]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.06it/s]\n",
      "[Epoch : 098]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.2972: 100%|\u001b[96m██████████\u001b[39m| [00:03<00:00,  5.75it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.5522 | Validation ROC-AUC : 0.8555]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00, 11.07it/s]\n",
      "[Epoch : 099]\n",
      "[Train(Epoch)-- Idx: 19| Train(Labeled) Loss : 0.3129: 100%|\u001b[96m██████████\u001b[39m| [00:02<00:00,  7.00it/s]\n",
      "[Val(Epoch)-- Idx: 3| Validation Loss : 0.4927 | Validation ROC-AUC : 0.8809]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  9.32it/s]\n",
      "[Val(Epoch)-- Idx: 3| Test Loss : 0.4945 | Test ROC-AUC : 0.8663]: 100%|\u001b[95m██████████\u001b[39m| [00:00<00:00,  7.08it/s]\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('./runs/EXP_0')\n",
    "model_sup = GINE(drop_ratio=0.3)\n",
    "test_metrics = run(model_sup, train_loader_labeled, val_loader, test_loader, writer, device, epochs=EPOCHS, exp_id=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지도 학습 기준 ROC-AUC가 0.8663을 기록하였습니다. 0.006의 상승폭을 보였으나, 단일 실험 결과이기 때문에 유의미한 결과라고 단정짓기는 어려울 것 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performance : ROC-AUC 0.8663\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Performance : ROC-AUC {test_metrics.roc_auc:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "본 튜토리얼에서는 Fixmatch를 활용하여 BACE 데이터셋에서 Unlabeled Data(QM9)을 사용하였을 경우 효과를 나타내는지에 대해 알아보았습니다. 결론은 아래와 같습니다.\n",
    "\n",
    "1. 소폭의 상승이 있었으나, 반복 실험을 통해 효과를 입증해야할 필요가 있습니다.\n",
    "2. 성능 상승 폭이 크지 않은 이유 중 하나로 BACE와 QM9 데이터셋에 들어있는 분자의 분포가 상이하기 때문이라고 추측합니다. __베타-세크리테이즈__ 라는 효소에 대해 억제성을 가지고 있는지에 대해 레이블이 되어있으며, __생물물리학__ 에 기반한 데이터셋인 반면, QM9 데이터의 경우 __양자역학__ 에 기반하여 데이터가 구축되어 있습니다. 따라서 차후 개선점으로는 QM9이 아니라 생물물리학 기반의 다른 데이터셋인 HIV나 MUV 데이터셋을 Unlabeled Data로 사용해볼 수 있을 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BA_chapter5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 14:38:14) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9379fe54c9df542b120525d7ee2a91c6f3975ec6dcea5b6f23b90f7a4c087769"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
